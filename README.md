# **FLAM â€“ Real-Time Android + OpenCV (C++) + OpenGL ES + Web Viewer**

A complete real-time image-processing pipeline built using Android (Kotlin), NDK/C++, OpenCV, OpenGL ES 2.0, and a TypeScript Web Viewer.

This project implements every requirement from the Android + OpenCV-C++ + OpenGL + Web R&D Internship Assessment.

---

# **Features Implemented**

## **Android (Kotlin + Native)**

- Real-time camera feed using **Camera2 (NV21 image stream)**
- JNI bridge for sending **NV21 â†’ C++** and receiving **RGBA buffer**
- Full OpenCV C++ processing:
  - RAW (RGBA)
  - Grayscale  
  - Canny Edge Detection (live sliders T1/T2)  
  - Threshold mode  
  - Motion Detection  
    - absdiff â†’ threshold â†’ contours  
    - red bounding boxes drawn directly on RGBA in native code
- **OpenGL ES 2.0 renderer**
  - GLSurfaceView + custom GLES2 renderer
  - Texture upload using ByteBuffer
  - Triangle-strip quad rendering
  - RENDERMODE_WHEN_DIRTY for low-latency
- **Stats panel (on device)**
  - FPS
  - Frame processing time (ms)
  - Resolution
- **Snapshot capture**
  - Rotate â†’ JPEG â†’ Base64
  - Auto-send to WebSocket server

---

## **Native (C++ / OpenCV / JNI)**

- NV21 â†’ BGR â†’ Gray â†’ RGBA conversions
- Canny (thresholds from UI)
- Threshold binary
- Motion detection with bounding rectangles
- Light morphology (noise reduction)
- All processing done in native C++ exactly as the assignment requires
- Efficient ByteBuffer return â†’ Kotlin â†’ OpenGL renderer

---

## **OpenGL ES Renderer**

- RGBA texture creation
- Dynamic reallocation on resolution change
- Texture upload via glTexSubImage2D
- Full-screen quad rendering
- Clean separation inside `/app/gl/`

---

## **Web Viewer (TypeScript)**

- Clean modular `/web/viewer` folder (TS + HTML)
- Live WebSocket frame display (**Base64 JPEG**)
- Fixed preview box (400Ã—400, object-fit contain)
- Shows:
  - Resolution
  - Timestamp
- Build system using TypeScript (`npm run serv`)
- Viewer dev/build using:
  - `npm run serv` (viewer)
  - `npm run dev` (server)

Assignment requires a TS-based web page that displays processed frames, which is implemented fully.

---

# **Architecture (Short & Clear)**


```txt
Camera (NV21)
        â†“
Kotlin (FrameExtractor)
        â†“
JNI (NativeBridge)
        â†“
C++ OpenCV Processing
      â€¢ Grayscale
      â€¢ Canny
      â€¢ Threshold
      â€¢ Motion Detection + Rectangles
        â†“
RGBA ByteArray
        â†“
OpenGL ES 2.0 Renderer (GLSurfaceView)
        â†“
Device Screen

Snapshot
        â†“
Rotate + JPEG + Base64
        â†“
WebSocket Client
        â†“
TypeScript Web Server
        â†“
Web Viewer (HTML + TS)
```

# **Project Structure**

```txt
FLAM/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/main/java/com/example/flam/
â”‚   â”‚      â”œâ”€â”€ data/
|              |_camera/        # CameraController, FrameExtractor
|              |_ nat/          # JNI bridge + NativeRepository
â”‚   â”‚          â””â”€â”€ web/         # WebSocket client
â”‚   â”‚      â”œâ”€â”€ gl/              # GLTextureRenderer (OpenGL ES)
â”‚   â”‚      â”œâ”€â”€ ui/              # Jetpack Compose UI
â”‚   â”‚      â””â”€â”€ web/             # WebSocket client
|
|
â”‚   â””â”€â”€ src/main/cpp/           # Native OpenCV C++ (NDK stable)
â”‚          â”œâ”€â”€ native_bridge.cpp
â”‚          â”œâ”€â”€ dummy.cpp
â”‚          â”œâ”€â”€ includes/
â”‚          â””â”€â”€ CMakeLists.txt
â”‚
â””â”€â”€ web/
    â”œâ”€â”€ server/                 # TypeScript WebSocket server
    â”‚     â”œâ”€â”€ src/server.ts
    â”‚     â””â”€â”€ package.json
          â””â”€â”€ tsconfig.json
    â”‚
    â””â”€â”€ web-viewer/             # TypeScript web viewer
          â”œâ”€â”€ src/viewer.ts
          â”œâ”€â”€ dist/
             â”œâ”€â”€ index.html
             â”œâ”€â”€ viewer.js
          â””â”€â”€ tsconfig.json
          â””â”€â”€ package.json

```

# **âš™ï¸ Setup Instructions**

## **Android Setup**

```txt
1. Install NDK + CMake from Android Studio â†’ SDK Tools
2. Open the project and let Gradle sync completely
3. Connect a physical Android device (Camera2 + OpenGL requires real hardware)
4. Run the app 
   â†’ Camera2 starts
   â†’ NV21 frames extracted
   â†’ JNI loads native library
   â†’ OpenCV processing runs (gray/canny/threshold/motion)
   â†’ OpenGL ES 2.0 renders RGBA output on screen
No additional configuration required.
CMake + Gradle automatically compile C++ and link OpenCV during build.
JNI â†’ C++ â†’ OpenCV pipeline is pre-wired through NativeBridge.
```
## **WebSocket Server Setup (TypeScript)**

```txt
cd web/server
npm install
npm run dev

Starts WebSocket server on:
    ws://<your-ip>:8080
    Change Ip addressin code also , as phone and pc needs to be on same local network for websocket.

cd web/viewer
npm install
npm run serv
```

# ğŸ“· Screenshots(All are motion detecting)

## Raw Mode
![Raw Mode](assets/raw.png)

## Gray Mode
![Gray Mode](assets/gray.png)

## Canny Mode
![Canny Mode](assets/canny.png)

## Threshold Mode
![Threshold Mode](assets/thresh.png)

## WebView Mode
![WebView Mode](assets/web.png)
